{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:00:01.856590Z",
     "iopub.status.busy": "2025-01-22T08:00:01.856403Z",
     "iopub.status.idle": "2025-01-22T08:00:11.796123Z",
     "shell.execute_reply": "2025-01-22T08:00:11.794582Z"
    }
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import lightning.pytorch as pl\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "\n",
    "# Paths for datasets\n",
    "train_data_dir = '../../dataset/tabula_sapiens_train_set_mapped.h5ad'\n",
    "val_data_dir = '../../dataset/tabula_sapiens_val_set_mapped.h5ad'\n",
    "test_data_dir = '../../dataset/tabula_sapiens_test_set_mapped.h5ad'\n",
    "\n",
    "# Load the datasets (no change in loading)\n",
    "adata_train = sc.read_h5ad(train_data_dir)\n",
    "adata_val = sc.read_h5ad(val_data_dir)\n",
    "adata_test = sc.read_h5ad(test_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:00:11.799846Z",
     "iopub.status.busy": "2025-01-22T08:00:11.799076Z",
     "iopub.status.idle": "2025-01-22T08:00:18.982690Z",
     "shell.execute_reply": "2025-01-22T08:00:18.981448Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata_train, target_sum=1e4)\n",
    "sc.pp.log1p(adata_train)\n",
    "\n",
    "sc.pp.normalize_total(adata_val, target_sum=1e4)\n",
    "sc.pp.log1p(adata_val)\n",
    "\n",
    "sc.pp.normalize_total(adata_test, target_sum=1e4)\n",
    "sc.pp.log1p(adata_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:00:18.985898Z",
     "iopub.status.busy": "2025-01-22T08:00:18.985476Z",
     "iopub.status.idle": "2025-01-22T08:00:29.903867Z",
     "shell.execute_reply": "2025-01-22T08:00:29.902727Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Take the union of all unique labels across the three datasets\n",
    "all_labels = np.concatenate([\n",
    "    adata_train.obs['cell_type'].values, \n",
    "    adata_val.obs['cell_type'].values, \n",
    "    adata_test.obs['cell_type'].values\n",
    "])\n",
    "\n",
    "# Step 2: Fit LabelEncoder on the combined labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Directly use the 'cell_type' column, assuming it is already encoded as int64\n",
    "X_train = adata_train.X.toarray()\n",
    "y_train = label_encoder.transform(adata_train.obs['cell_type'])\n",
    "\n",
    "X_val = adata_val.X\n",
    "y_val = label_encoder.transform(adata_val.obs['cell_type'])\n",
    "\n",
    "X_test = adata_test.X\n",
    "y_test = label_encoder.transform(adata_test.obs['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:00:29.906497Z",
     "iopub.status.busy": "2025-01-22T08:00:29.906304Z",
     "iopub.status.idle": "2025-01-22T08:01:21.331415Z",
     "shell.execute_reply": "2025-01-22T08:01:21.330227Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 64\n",
    "pca = PCA(n_components=n_components)\n",
    "train_embeddings = pca.fit_transform(X_train)\n",
    "val_embeddings = pca.transform(X_val)\n",
    "test_embeddings = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:01:21.355711Z",
     "iopub.status.busy": "2025-01-22T08:01:21.342601Z",
     "iopub.status.idle": "2025-01-22T08:01:22.166102Z",
     "shell.execute_reply": "2025-01-22T08:01:22.165392Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "    # 初始化和训练KNN分类器\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(val_embeddings, y_val)\n",
    "    \n",
    "    # 模型预测\n",
    "predictions = knn.predict(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:01:22.168819Z",
     "iopub.status.busy": "2025-01-22T08:01:22.168326Z",
     "iopub.status.idle": "2025-01-22T08:01:22.678681Z",
     "shell.execute_reply": "2025-01-22T08:01:22.677983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.7870209663982227\n",
      "Weighted F1 Score: 0.771187745907886\n",
      "Macro F1 Score: 0.5663548548929224\n",
      "                                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                                                    B cell       0.77      0.50      0.61       154\n",
      "                     CD16-negative, CD56-bright natural killer cell, human       0.66      0.69      0.67       555\n",
      "                                                CD4-positive helper T cell       0.72      0.78      0.75      5067\n",
      "                                 CD4-positive, alpha-beta cytotoxic T cell       0.20      0.15      0.17       567\n",
      "                                 CD8-positive, alpha-beta cytotoxic T cell       0.59      0.88      0.70      7122\n",
      "                            central memory CD8-positive, alpha-beta T cell       0.66      0.30      0.42      2156\n",
      "                                              class switched memory B cell       0.52      0.63      0.57       323\n",
      "                                                        classical monocyte       0.94      0.98      0.96      8950\n",
      "                                               conventional dendritic cell       0.80      0.30      0.43       326\n",
      "                                                            dendritic cell       0.00      0.00      0.00         5\n",
      "                           effector memory CD8-positive, alpha-beta T cell       0.38      0.11      0.18       393\n",
      "effector memory CD8-positive, alpha-beta T cell, terminally differentiated       0.28      0.12      0.17      1463\n",
      "                                                               erythrocyte       1.00      0.25      0.40         4\n",
      "                                                        gamma-delta T cell       0.58      0.20      0.29      1143\n",
      "                                                               granulocyte       1.00      0.67      0.80         3\n",
      "                                                      innate lymphoid cell       0.50      0.20      0.28        41\n",
      "                                                          mature NK T cell       0.15      0.01      0.03       138\n",
      "                                                  mucosal invariant T cell       0.77      0.52      0.62       772\n",
      "                                                              naive B cell       0.92      0.98      0.95      4075\n",
      "                      naive thymus-derived CD4-positive, alpha-beta T cell       0.80      0.91      0.85      9923\n",
      "                      naive thymus-derived CD8-positive, alpha-beta T cell       0.87      0.62      0.72      2835\n",
      "                                                       natural killer cell       0.89      0.84      0.86      8576\n",
      "                                                    non-classical monocyte       0.90      0.78      0.84      1408\n",
      "                                                               plasma cell       0.97      0.78      0.86       109\n",
      "                                                               plasmablast       0.50      0.25      0.33         4\n",
      "                                               plasmacytoid dendritic cell       0.97      0.78      0.87       236\n",
      "                                                                  platelet       1.00      1.00      1.00       292\n",
      "                                                         regulatory T cell       0.79      0.39      0.52       976\n",
      "\n",
      "                                                                  accuracy                           0.79     57616\n",
      "                                                                 macro avg       0.68      0.52      0.57     57616\n",
      "                                                              weighted avg       0.78      0.79      0.77     57616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanchuangyi/miniconda3/envs/ssl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hanchuangyi/miniconda3/envs/ssl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hanchuangyi/miniconda3/envs/ssl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings, predictions and label mapping to ./prediction_results/PCA_seed_42\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(np.concatenate([y_test, predictions]))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)  \n",
    "f1 = f1_score(y_test, predictions, average='weighted')  \n",
    "macro_f1 = f1_score(y_test, predictions, average='macro')  \n",
    "\n",
    "print(f\"KNN Accuracy: {accuracy}\")  \n",
    "print(f\"Weighted F1 Score: {f1}\")  \n",
    "print(f\"Macro F1 Score: {macro_f1}\")  \n",
    "\n",
    "# Get the class names for only the classes present in the data  \n",
    "present_classes = [label_encoder.classes_[i] for i in unique_classes]  \n",
    "report = classification_report(y_test, predictions,   \n",
    "                             labels=unique_classes,  # specify which labels to include  \n",
    "                             target_names=present_classes)  # their corresponding names  \n",
    "print(report)  \n",
    "\n",
    "# Optionally, print which class is missing  \n",
    "all_classes_set = set(range(len(label_encoder.classes_)))  \n",
    "present_classes_set = set(unique_classes)  \n",
    "missing_classes = all_classes_set - present_classes_set  \n",
    "if missing_classes:  \n",
    "    print(\"\\nMissing class indices:\", missing_classes)  \n",
    "    print(\"Missing class names:\", [label_encoder.classes_[i] for i in missing_classes])\n",
    "    \n",
    "random_seed = 42\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create directory to store embeddings and predictions\n",
    "output_dir = os.path.join('./prediction_results', f'PCA_seed_{random_seed}')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save embeddings\n",
    "np.save(os.path.join(output_dir, 'train_embeddings.npy'), train_embeddings)\n",
    "np.save(os.path.join(output_dir, 'val_embeddings.npy'), val_embeddings) \n",
    "np.save(os.path.join(output_dir, 'test_embeddings.npy'), test_embeddings)\n",
    "\n",
    "# Save predictions and ground truth\n",
    "np.save(os.path.join(output_dir, 'test_predictions.npy'), predictions)\n",
    "np.save(os.path.join(output_dir, 'test_ground_truth.npy'), y_test)\n",
    "np.save(os.path.join(output_dir, 'train_ground_truth.npy'), y_train)\n",
    "np.save(os.path.join(output_dir, 'val_ground_truth.npy'), y_val)\n",
    "\n",
    "# Save training history if exists\n",
    "if 'train_losses' in globals() and 'val_losses' in globals():\n",
    "    np.save(os.path.join(output_dir, 'train_losses.npy'), np.array(train_losses))\n",
    "    np.save(os.path.join(output_dir, 'val_losses.npy'), np.array(val_losses))\n",
    "\n",
    "# Save label encoder classes (target names)\n",
    "label_mapping = {i: label_name for i, label_name in enumerate(label_encoder.classes_)}\n",
    "with open(os.path.join(output_dir, 'label_mapping.json'), 'w') as f:\n",
    "    json.dump(label_mapping, f, indent=4)\n",
    "\n",
    "print(f\"Saved embeddings, predictions and label mapping to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T08:01:22.680438Z",
     "iopub.status.busy": "2025-01-22T08:01:22.680268Z",
     "iopub.status.idle": "2025-01-22T08:01:22.690454Z",
     "shell.execute_reply": "2025-01-22T08:01:22.689870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Summary:\n",
      "macro_f1\tweighted_f1\tmicro_f1\n",
      "0.566\t0.771\t0.787\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 当前 Notebook 文件名\n",
    "notebook_name = \"tabula_sapiens_PCA_42.ipynb\"\n",
    "\n",
    "# 初始化需要打印的值\n",
    "init_train_loss = train_losses[0] if 'train_losses' in globals() else None\n",
    "init_val_loss = val_losses[0] if 'val_losses' in globals() else None\n",
    "converged_epoch = len(train_losses) - patience if 'train_losses' in globals() else None\n",
    "converged_val_loss = best_val_loss if 'best_val_loss' in globals() else None\n",
    "\n",
    "# 打印所有所需的指标\n",
    "print(\"Metrics Summary:\")\n",
    "if 'train_losses' in globals():\n",
    "    print(f\"init_train_loss\\tinit_val_loss\\tconverged_epoch\\tconverged_val_loss\\tmacro_f1\\tweighted_f1\\tmicro_f1\")\n",
    "    print(f\"{init_train_loss:.3f}\\t{init_val_loss:.3f}\\t{converged_epoch}\\t{converged_val_loss:.3f}\\t{macro_f1:.3f}\\t{f1:.3f}\\t{accuracy:.3f}\")\n",
    "else:\n",
    "    print(f\"macro_f1\\tweighted_f1\\tmicro_f1\")\n",
    "    print(f\"{macro_f1:.3f}\\t{f1:.3f}\\t{accuracy:.3f}\")\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "output_data = {\n",
    "    'dataset_split_random_seed': [int(random_seed)],\n",
    "    'dataset': ['Tabula Sapiens'],\n",
    "    'method': [re.search(r'tabula_sapiens_(.*?)_\\d+', notebook_name).group(1)],\n",
    "    'init_train_loss': [init_train_loss if init_train_loss is not None else ''],\n",
    "    'init_val_loss': [init_val_loss if init_val_loss is not None else ''],\n",
    "    'converged_epoch': [converged_epoch if converged_epoch is not None else ''],\n",
    "    'converged_val_loss': [converged_val_loss if converged_val_loss is not None else ''],\n",
    "    'macro_f1': [macro_f1],\n",
    "    'weighted_f1': [f1],\n",
    "    'micro_f1': [accuracy]\n",
    "}\n",
    "output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# 保存到当前目录下名为 results 的文件夹中\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "\n",
    "csv_filename = f\"results/{os.path.splitext(notebook_name)[0]}_results.csv\"\n",
    "output_df.to_csv(csv_filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
